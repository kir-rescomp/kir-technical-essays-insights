{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>       Technical articles about HPC, BioInformatics/Computational Biology,        Scientific Computing and Experimental Methods     </p> <p> Workshops  HPC  Bioinformatics  Containers  Programming </p> Latest Content <ul> <li> <p></p> Featured Posts<p></p> <p>Hand-picked articles covering important topics in research computing</p> <p>View Featured</p> </li> <li> <p></p> All Posts<p></p> <p>Browse the complete archive of technical articles and tutorials</p> <p>View All Posts </p> </li> </ul>"},{"location":"#featured-posts-heading","title":"Featured Posts","text":"<ul> <li> <p> Importance of Unit Testing</p> <p>Unit testing is crucial in software development because it verifies individual code units in  isolation, enabling early bug detection, improved code quality, and greater confidence during refactoring and maintenance</p> <p> Read more</p> <p> Nov 28, 2024 \u00b7  7 min read</p> </li> <li> <p> Version Control with Git: A Technical Primer</p> <p>Why <code>Git</code> matters</p> <p> Read more</p> <p> Nov 15, 2024 \u00b7  5 min read</p> </li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/unit-testing/","title":"Unit testing","text":"","tags":["Testing","Python"]},{"location":"blog/unit-testing/#unit-testing-for-research-software-a-practical-guide","title":"Unit Testing for Research Software: A Practical Guide","text":"<p>Scientific software powers modern research, from analyzing genomic sequences to simulating climate models. Yet much of this software is written by researchers who are self-taught programmers, often under pressure to produce results quickly. Unit testing might seem like an extra burden, but it's actually a fundamental practice that makes your research more reliable, your code easier to maintain, and your findings more reproducible.</p> <p>What is Unit Testing?</p> <p>Unit testing is the practice of writing small, focused tests that verify individual components (or \"units\") of your code work correctly in isolation. Think of it as checking each instrument in your lab before running an experiment, rather than waiting until the end to discover something was miscalibrated. Let's look at a concrete example from computational biology. Suppose you're writing a tool to calculate quality scores from FASTQ files\u2014a common task when processing sequencing data:</p> <p></p><pre><code># seq_quality.py\ndef phred_to_prob(phred_score):\n    \"\"\"Convert Phred quality score to error probability.\"\"\"\n    return 10 ** (-phred_score / 10)\n\ndef average_quality(quality_string):\n    \"\"\"Calculate average Phred score from ASCII quality string.\"\"\"\n    if not quality_string:\n        raise ValueError(\"Quality string cannot be empty\")\n\n    # FASTQ uses ASCII offset of 33\n    scores = [ord(char) - 33 for char in quality_string]\n    return sum(scores) / len(scores)\n</code></pre> Here are the unit tests for these functions:<p></p> <pre><code># test_seq_quality.py\nimport pytest\nfrom seq_quality import phred_to_prob, average_quality\n\ndef test_phred_conversion_perfect_quality():\n    \"\"\"Test Phred score of 40 (99.99% accuracy).\"\"\"\n    assert abs(phred_to_prob(40) - 0.0001) &lt; 1e-6\n\ndef test_phred_conversion_poor_quality():\n    \"\"\"Test Phred score of 10 (90% accuracy).\"\"\"\n    assert abs(phred_to_prob(10) - 0.1) &lt; 1e-6\n\ndef test_average_quality_uniform():\n    \"\"\"Test with uniform quality scores.\"\"\"\n    # 'III' = ASCII 73, Phred = 73-33 = 40\n    result = average_quality(\"III\")\n    assert result == 40.0\n\ndef test_average_quality_mixed():\n    \"\"\"Test with varied quality scores.\"\"\"\n    # '!~' = ASCII 33 and 126, Phred 0 and 93\n    result = average_quality(\"!~\")\n    assert result == 46.5\n\ndef test_average_quality_empty_string():\n    \"\"\"Test error handling for empty input.\"\"\"\n    with pytest.raises(ValueError):\n        average_quality(\"\")\n</code></pre> <p>Each test is independent, runs in milliseconds, and checks one specific behavior. If <code>test_phred_conversion_perfect_quality</code> fails, you know exactly where the problem is.</p>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#why-unit-testing-matters-for-research-software","title":"Why Unit Testing Matters for Research Software","text":"","tags":["Testing","Python"]},{"location":"blog/unit-testing/#reproducibility","title":"Reproducibility","text":"<p>Research depends on reproducibility, yet computational results can be surprisingly fragile. A subtle bug in your analysis pipeline might go undetected for months, potentially affecting published results. Unit tests provide a safety net: if your tests pass, you have confidence that the core logic hasn't been accidentally broken.</p>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#collaboration-and-reuse","title":"Collaboration and Reuse","text":"<p>Research software is increasingly collaborative. When a colleague contributes code or you return to your own code after six months, unit tests document expected behavior and catch unintended changes. They're executable documentation that never goes out of date.</p>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#complex-environments","title":"Complex Environments","text":"<p>If you work with HPC clusters, you know that software behavior can vary across environments\u2014different library versions, compilers, or container configurations. Unit tests help verify that your code behaves identically whether running on your laptop, in an Apptainer container, or on a compute node with 8 GPUs.</p>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#confidence-to-refactor","title":"Confidence to Refactor","text":"<p>Scientific code often needs optimization. Perhaps your Python script needs to be 10x faster, or you're switching from NumPy to CuPy for GPU acceleration. Unit tests let you refactor aggressively while ensuring correctness isn't sacrificed for performance.</p>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#catching-edge-cases","title":"Catching Edge Cases","text":"<p>Research data is messy. Empty files, negative values where you expected positive, Unicode characters in supposedly ASCII data\u2014unit tests force you to think through these scenarios before they cause a job to fail after running for 48 hours on a cluster.</p>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#core-fundamental-rules","title":"Core Fundamental Rules","text":"<ol> <li>Test One Thing at a Time Each test should verify a single, specific behavior. If a test fails, you should immediately know what went wrong without debugging.</li> </ol> <p>Good:</p> <pre><code>def test_reverse_complement_single_nucleotide():\n    assert reverse_complement(\"A\") == \"T\"\n\ndef test_reverse_complement_sequence():\n    assert reverse_complement(\"ATCG\") == \"CGAT\"\n</code></pre> <p>Bad:</p> <p></p><pre><code>def test_reverse_complement():\n    assert reverse_complement(\"A\") == \"T\"\n    assert reverse_complement(\"ATCG\") == \"CGAT\"\n    assert reverse_complement(\"\") == \"\"\n    # If this fails, which case broke?\n</code></pre> 2. Tests Must Be Independent Tests should not depend on each other or share state. They should run successfully in any order, in parallel, or in isolation.<p></p> <p>Bad:</p> <pre><code># test_analysis.py\nresults = None  # Shared state!\n\ndef test_load_data():\n    global results\n    results = load_dataset(\"data.csv\")\n    assert results is not None\n\ndef test_calculate_mean():\n    # Depends on test_load_data running first!\n    assert calculate_mean(results) &gt; 0\n</code></pre> <ol> <li> <p>Tests Should Be Fast Unit tests should run in milliseconds, not minutes. If you need to test with real data files or database connections, those are integration tests\u2014still valuable, but separate from unit tests. Fast tests mean you'll actually run them frequently.</p> </li> <li> <p>Use Descriptive Names Test names should describe what they're testing and what the expected outcome is. When a test fails in a CI/CD pipeline at 2 AM, good names are invaluable.</p> </li> </ol> <p>Good:</p> <p></p><pre><code>def test_parse_fasta_handles_multiline_sequences()\ndef test_alignment_score_returns_zero_for_empty_sequences()\ndef test_calculate_gc_content_raises_error_on_invalid_characters()\n</code></pre> Bad:<p></p> <p></p><pre><code>def test1()\ndef test_fasta()\ndef test_edge_case()\n</code></pre> 5. Test Both Success and Failure Don't just test the happy path. Test error conditions, edge cases, and boundary values.<p></p> <p></p><pre><code>def test_normalize_expression_positive_values():\n    \"\"\"Normal case: positive expression values.\"\"\"\n    result = normalize([1.0, 2.0, 3.0])\n    assert sum(result) == pytest.approx(1.0)\n\ndef test_normalize_expression_with_zeros():\n    \"\"\"Edge case: some zero values.\"\"\"\n    result = normalize([0.0, 1.0, 2.0])\n    assert result[0] == 0.0\n\ndef test_normalize_expression_all_zeros():\n    \"\"\"Failure case: cannot normalize all zeros.\"\"\"\n    with pytest.raises(ValueError):\n        normalize([0.0, 0.0, 0.0])\n</code></pre> 6. Avoid Testing Implementation Details Test the public interface and behavior, not internal implementation. This gives you freedom to refactor without rewriting tests.<p></p> <ol> <li>Make Failures Informative Use assertion messages or pytest's built-in failure output to make debugging easier.</li> </ol> <pre><code>def test_quality_threshold():\n    reads = filter_by_quality(fastq_data, min_quality=30)\n    assert len(reads) &gt; 0, f\"Expected filtered reads, got {len(reads)}\"\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#getting-started-a-practical-guide","title":"Getting Started: A Practical Guide","text":"<p>Installing pytest</p> <pre><code>pip install pytest\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#writing-your-first-test","title":"Writing Your First Test","text":"<p>Create a file starting with test_ (e.g., test_mycode.py). Write functions starting with test_:</p> <pre><code># test_mycode.py\ndef test_addition():\n    assert 1 + 1 == 2\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests in current directory\npytest\n\n# Run specific test file\npytest test_mycode.py\n\n# Run tests matching a pattern\npytest -k \"quality\"\n\n# Show print statements (useful for debugging)\npytest -s\n\n# Stop at first failure\npytest -x\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#structuring-your-project","title":"Structuring Your Project","text":"<pre><code>my_project/\n\u251c\u2500\u2500 mypackage/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 analysis.py\n\u2502   \u2514\u2500\u2500 utils.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_analysis.py\n\u2502   \u2514\u2500\u2500 test_utils.py\n\u251c\u2500\u2500 setup.py\n\u2514\u2500\u2500 README.md\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#common-pitfalls-in-scientific-computing","title":"Common Pitfalls in Scientific Computing","text":"","tags":["Testing","Python"]},{"location":"blog/unit-testing/#floating-point-comparisons","title":"Floating Point Comparisons","text":"<p>Never use exact equality for floating-point numbers:</p> <p>Bad:</p> <pre><code>def test_mean():\n    assert calculate_mean([1.0, 2.0, 3.0]) == 2.0\n</code></pre> <p>Good:</p> <pre><code>def test_mean():\n    assert calculate_mean([1.0, 2.0, 3.0]) == pytest.approx(2.0)\n    # or\n    assert abs(calculate_mean([1.0, 2.0, 3.0]) - 2.0) &lt; 1e-10\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#random-number-generation","title":"Random Number Generation","text":"<p>Set seeds for reproducibility:</p> <pre><code>def test_random_sampling():\n    import random\n    random.seed(42)\n    sample = random_sample(population, size=10)\n    assert len(sample) == 10\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#file-io","title":"File I/O","text":"<p>Use temporary files or fixtures instead of relying on external files:</p> <pre><code>import tempfile\nimport pytest\n\n@pytest.fixture\ndef temp_fasta():\n    with tempfile.NamedTemporaryFile(mode='w', suffix='.fasta', delete=False) as f:\n        f.write(\"&gt;seq1\\nATCG\\n\")\n        f.write(\"&gt;seq2\\nGCTA\\n\")\n        return f.name\n\ndef test_parse_fasta(temp_fasta):\n    sequences = parse_fasta(temp_fasta)\n    assert len(sequences) == 2\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#external-dependencies","title":"External Dependencies","text":"<p>Mock external services or databases:</p> <pre><code>from unittest.mock import Mock, patch\n\ndef test_fetch_gene_info():\n    with patch('mycode.ncbi_api.fetch') as mock_fetch:\n        mock_fetch.return_value = {'gene': 'BRCA1', 'chromosome': 17}\n        result = get_gene_location('BRCA1')\n        assert result['chromosome'] == 17\n</code></pre>","tags":["Testing","Python"]},{"location":"blog/unit-testing/#final-thoughts","title":"Final Thoughts","text":"<p>Unit testing isn't about achieving 100% code coverage or writing tests for the sake of writing tests. It's about building confidence in your code and making your research more reliable. Start small: pick one function that's been causing problems and write a few tests for it. Run them. See a bug get caught before it reaches production. You'll quickly see the value. Remember, every test you write is a bug you won't have to debug at midnight before a conference deadline. Your future self\u2014and your collaborators\u2014will thank you.</p> <p>Start with one test today. Your research deserves it.</p>","tags":["Testing","Python"]},{"location":"blog/vc-git-technical-primer/","title":"vc git Technical primer","text":"","tags":["Git"]},{"location":"blog/vc-git-technical-primer/#version-control-with-git-a-technical-primer","title":"Version Control with Git: A Technical Primer","text":"<p>Version control is the practice of tracking and managing changes to code over time. Git, created by Linus Torvalds in 2005, has become the dominant distributed version control system in software development.</p>","tags":["Git"]},{"location":"blog/vc-git-technical-primer/#core-concepts","title":"Core Concepts","text":"<p>At its heart, Git maintains a directed acyclic graph (DAG) of commits. Each commit is a snapshot of your project at a specific point in time, identified by a SHA-1 hash. Unlike centralized systems like SVN, Git is distributed\u2014every developer has a complete copy of the repository history.</p> <p>The fundamental workflow involves three areas:</p> <ul> <li>Working directory: Your current files</li> <li>Staging area (index): Changes marked for the next commit</li> <li>Repository: Committed snapshots</li> </ul> <p>This staging area is Git's distinguishing feature, allowing you to craft precise commits by selectively adding changes.</p>","tags":["Git"]},{"location":"blog/vc-git-technical-primer/#branching-and-merging","title":"Branching and Merging","text":"<p>Git's lightweight branching model is revolutionary. A branch is simply a movable pointer to a commit. Creating, switching, and merging branches is fast and cheap, encouraging workflows like feature branches and GitFlow.</p> <p>When merging, Git performs a three-way merge using the common ancestor of both branches. Conflicts arise when the same lines are modified differently, requiring manual resolution.</p>","tags":["Git"]},{"location":"blog/vc-git-technical-primer/#practical-operations","title":"Practical Operations","text":"<p>Common operations include:</p> <ul> <li><code>git init</code> or <code>git clone</code> to start</li> <li><code>git add</code> to stage changes</li> <li><code>git commit</code> to snapshot</li> <li><code>git push/pull</code> to sync with remotes</li> <li><code>git branch</code> and <code>git merge</code> for parallel development</li> </ul> <p>Advanced features like rebase, cherry-pick, and interactive staging enable powerful history manipulation.</p>","tags":["Git"]},{"location":"blog/vc-git-technical-primer/#why-git-matters","title":"Why Git Matters","text":"<p>Git enables collaborative development at scale. It provides complete history, enables experimentation through branching, and allows offline work. The GitHub/GitLab ecosystem built atop Git has transformed how software is developed and shared.</p> <p>Understanding Git's content-addressable storage model and object database\u2014where blobs, trees, commits, and tags form the foundation\u2014unlocks mastery of this essential tool.</p>","tags":["Git"]},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2025/#2025","title":"2025","text":""},{"location":"blog/category/programming/","title":"Programming","text":""},{"location":"blog/category/programming/#programming","title":"Programming","text":""},{"location":"blog/category/versionion-control/","title":"Versionion Control","text":""},{"location":"blog/category/versionion-control/#versionion-control","title":"Versionion Control","text":""},{"location":"blog/page/2/","title":"Blog","text":""},{"location":"blog/page/2/#blog","title":"Blog","text":""},{"location":"blog/archive/2025/page/2/","title":"2025","text":""},{"location":"blog/archive/2025/page/2/#2025","title":"2025","text":""}]}